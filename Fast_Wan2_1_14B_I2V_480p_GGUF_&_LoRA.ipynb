{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **WAN IMAGE TO VIDEO WITH Q4 & Q6 GGUF MODELS, LORA, & TEACACHE**\n",
        "- You can use the free T4 GPU to run this notebook with the default Q4 GGUF model. I recommend that you use higher GPUs for the Q6 GGUF model.\n",
        "- **To use a lora, put its huggingface download link in the `lora_hf_download_url` textbox or select the `download_lora_from_civitai` checkbox and input a LoRA's download link and your civitai token before running the code to `Prepare Environment`. Remember to describe the main subject of the image and include the trigger words for the LoRA in the prompt. For the default rotation lora, the trigger word is r0t4tion 360 degrees rotation. You can get LoRAs from this huggingface repository: https://huggingface.co/collections/Remade-AI/wan21-14b-480p-i2v-loras-67d0e26f08092436b585919b and from civitai: https://civitai.com/models. In civitai, set the `Wan Video` and `LoRA` filters to see the Wan LoRAs.**\n",
        "- Generating a video from this flux image (https://comfyanonymous.github.io/ComfyUI_examples/flux/) with the settings (480x480, 20 steps, 65 frames) using the Q4 GGUF model and the free T4 GPU took about 33 minutes with no Teacache i.e. `rel_l1_threshless` set to zero in the Teacache settings, and less than 18 minutes with `rel_l1_threshless` set to 0.275 with little loss in quality. Increase the value of `rel_l1_threshless` for faster generation with a tradeoff in quality.\n",
        "- The videos are generated at 16fps. You can use the `Frame Interpolation` notebook in this github repository (https://github.com/Isi-dev/Google-Colab_Notebooks) to increase it."
      ],
      "metadata": {
        "id": "D2lupAO0HdyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "96675e45HYsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253dc0f4-0f32-4e4a-c991-404314535dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Environment Setup Complete!\n"
          ]
        }
      ],
      "source": [
        "# @title Prepare Environment\n",
        "!pip install --upgrade --quiet torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%cd /content\n",
        "from IPython.display import clear_output\n",
        "!pip install -q torchsde einops diffusers accelerate xformers triton sageattention\n",
        "!pip install av\n",
        "clear_output()\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "clear_output()\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_KJNodes.git\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_KJNodes\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "%cd /content/ComfyUI\n",
        "!apt -y install -qq aria2 ffmpeg\n",
        "clear_output()\n",
        "\n",
        "useQ6 = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "lora = \"flyingEffect.safetensors\"\n",
        "\n",
        "lora_hf_download_url = \"https://huggingface.co/Remade-AI/Rotate/resolve/main/rotate_20_epochs.safetensors\"# @param {\"type\":\"string\"}\n",
        "download_lora_from_civitai = False # @param {\"type\":\"boolean\"}\n",
        "lora_civitai_download_url = \"https://civitai.com/api/download/models/1523247?type=Model&format=SafeTensor\"# @param {\"type\":\"string\"}\n",
        "civitai_token = \"Put your civitai token here\"# @param {\"type\":\"string\"}\n",
        "\n",
        "def download_with_aria2c(link, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "\n",
        "    filename = link.split(\"/\")[-1]\n",
        "    command = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d {folder} -o {filename}\"\n",
        "\n",
        "    print(\"Executing download command:\")\n",
        "    print(command)\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    get_ipython().system(command)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "\n",
        "def download_civitai_model(civitai_link, civitai_token, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "    import time\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        model_id = civitai_link.split(\"/models/\")[1].split(\"?\")[0]\n",
        "    except IndexError:\n",
        "        raise ValueError(\"Invalid Civitai URL format. Please use a link like: https://civitai.com/api/download/models/1523247?...\")\n",
        "\n",
        "    civitai_url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
        "    if civitai_token:\n",
        "        civitai_url += f\"&token={civitai_token}\"\n",
        "\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"model_{timestamp}.safetensors\"\n",
        "\n",
        "    full_path = os.path.join(folder, filename)\n",
        "\n",
        "    download_command = f\"wget --max-redirect=10 --show-progress \\\"{civitai_url}\\\" -O \\\"{full_path}\\\"\"\n",
        "    print(\"Downloading from Civitai...\")\n",
        "\n",
        "    os.system(download_command)\n",
        "\n",
        "    local_path = os.path.join(folder, filename)\n",
        "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
        "        print(f\"LoRA downloaded successfully: {local_path}\")\n",
        "    else:\n",
        "        print(f\"❌ LoRA download failed or file is empty: {local_path}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "    CheckpointLoaderSimple,\n",
        "    CLIPLoader,\n",
        "    CLIPTextEncode,\n",
        "    VAEDecode,\n",
        "    VAELoader,\n",
        "    KSampler,\n",
        "    UNETLoader,\n",
        "    LoadImage,\n",
        "    CLIPVisionLoader,\n",
        "    CLIPVisionEncode,\n",
        "    LoraLoaderModelOnly\n",
        ")\n",
        "\n",
        "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
        "from custom_nodes.ComfyUI_KJNodes.nodes.model_optimization_nodes import (\n",
        "    WanVideoTeaCacheKJ,\n",
        "    PathchSageAttentionKJ\n",
        ")\n",
        "\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "from comfy_extras.nodes_images import SaveAnimatedWEBP\n",
        "from comfy_extras.nodes_video import SaveWEBM\n",
        "from comfy_extras.nodes_wan import WanImageToVideo\n",
        "\n",
        "if download_lora_from_civitai:\n",
        "    lora = download_civitai_model(lora_civitai_download_url, civitai_token)\n",
        "else:\n",
        "    lora = download_with_aria2c(lora_hf_download_url)\n",
        "\n",
        "\n",
        "if useQ6:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/resolve/main/wan2.1-i2v-14b-480p-Q6_K.gguf -d /content/ComfyUI/models/unet -o wan2.1-i2v-14b-480p-Q6_K.gguf\n",
        "else:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/resolve/main/wan2.1-i2v-14b-480p-Q4_0.gguf -d /content/ComfyUI/models/unet -o wan2.1-i2v-14b-480p-Q4_0.gguf\n",
        "clear_output()\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors -d /content/ComfyUI/models/text_encoders -o umt5_xxl_fp8_e4m3fn_scaled.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors -d /content/ComfyUI/models/vae -o wan_2.1_vae.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors -d /content/ComfyUI/models/clip_vision -o clip_vision_h.safetensors\n",
        "clear_output()\n",
        "# Initialize nodes\n",
        "unet_loader = UnetLoaderGGUF()\n",
        "pathch_sage_attention = PathchSageAttentionKJ()\n",
        "teacache = WanVideoTeaCacheKJ()\n",
        "model_sampling = ModelSamplingSD3()\n",
        "clip_loader = CLIPLoader()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "vae_loader = VAELoader()\n",
        "clip_vision_loader = CLIPVisionLoader()\n",
        "clip_vision_encode = CLIPVisionEncode()\n",
        "load_image = LoadImage()\n",
        "wan_image_to_video = WanImageToVideo()\n",
        "ksampler = KSampler()\n",
        "vae_decode = VAEDecode()\n",
        "save_webp = SaveAnimatedWEBP()\n",
        "save_webm = SaveWEBM()\n",
        "load_lora = LoraLoaderModelOnly()\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "    with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webp(images, filename_prefix, fps, quality=90, lossless=False, method=4, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as animated WEBP using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webp\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'lossless': bool(lossless),\n",
        "        'method': int(method)\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='WEBP',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webm(images, filename_prefix, fps, codec=\"vp9\", quality=32, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as WEBM using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webm\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'codec': str(codec),\n",
        "        'output_params': ['-crf', str(int(quality))]\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='FFMPEG',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save single frame as PNG image.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
        "\n",
        "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(frame).save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def upload_image():\n",
        "    \"\"\"Handle image upload in Colab and store in /content/ComfyUI/input/\"\"\"\n",
        "    from google.colab import files\n",
        "    import os\n",
        "    import shutil\n",
        "\n",
        "    os.makedirs('/content/ComfyUI/input', exist_ok=True)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move each uploaded file to ComfyUI input directory\n",
        "    for filename in uploaded.keys():\n",
        "        src_path = f'/content/ComfyUI/{filename}'\n",
        "        dest_path = f'/content/ComfyUI/input/{filename}'\n",
        "\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\"Image saved to: {dest_path}\")\n",
        "        return dest_path\n",
        "\n",
        "    return None\n",
        "\n",
        "def generate_video(\n",
        "    image_path: str = None,\n",
        "    LoRA_Strength: float = 1.00,\n",
        "    rel_l1_thresh: float = 0.275,\n",
        "    start_percent: float = 0.1,\n",
        "    end_percent: float = 1.0,\n",
        "    positive_prompt: str = \"a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around\",\n",
        "    negative_prompt: str = \"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    width: int = 832,\n",
        "    height: int = 480,\n",
        "    seed: int = 82628696717253,\n",
        "    steps: int = 20,\n",
        "    cfg_scale: float = 1.0,\n",
        "    sampler_name: str = \"uni_pc\",\n",
        "    scheduler: str = \"simple\",\n",
        "    frames: int = 33,\n",
        "    fps: int = 16,\n",
        "    output_format: str = \"mp4\",\n",
        "    overwrite: bool = False,\n",
        "    use_lora: bool = True,\n",
        "    use_sage_attention: bool = True,\n",
        "    enable_flow_shift: bool = True,\n",
        "    shift: float = 8.0\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(\"umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"wan\", \"default\")[0]\n",
        "\n",
        "        positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "        negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        if image_path is None:\n",
        "            print(\"Please upload an image file:\")\n",
        "            image_path = upload_image()\n",
        "        if image_path is None:\n",
        "            print(\"No image uploaded!\")\n",
        "        loaded_image = load_image.load_image(image_path)[0]\n",
        "        clip_vision = clip_vision_loader.load_clip(\"clip_vision_h.safetensors\")[0]\n",
        "        clip_vision_output = clip_vision_encode.encode(clip_vision, loaded_image, \"none\")[0]\n",
        "\n",
        "        del clip_vision\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Loading VAE...\")\n",
        "        vae = vae_loader.load_vae(\"wan_2.1_vae.safetensors\")[0]\n",
        "\n",
        "        positive_out, negative_out, latent = wan_image_to_video.encode(\n",
        "            positive, negative, vae, width, height, frames, 1, loaded_image, clip_vision_output\n",
        "        )\n",
        "\n",
        "        print(\"Loading Unet Model...\")\n",
        "        if useQ6:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q6_K.gguf\")[0]\n",
        "        else:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q4_0.gguf\")[0]\n",
        "\n",
        "        if enable_flow_shift:\n",
        "            model = model_sampling.patch(model, shift)[0]\n",
        "\n",
        "        if use_lora:\n",
        "            print(\"Loading Lora...\")\n",
        "            model = load_lora.load_lora_model_only(model, lora, LoRA_Strength)[0]\n",
        "\n",
        "        if use_sage_attention:\n",
        "            model = pathch_sage_attention.patch(model, \"auto\")[0]\n",
        "\n",
        "        if rel_l1_thresh > 0:\n",
        "            print(\"Setting Teacache...\")\n",
        "            model = teacache.patch_teacache(model, rel_l1_thresh, start_percent, end_percent, \"main_device\", \"i2v_480\")[0]\n",
        "\n",
        "        print(\"Generating video...\")\n",
        "        sampled = ksampler.sample(\n",
        "            model=model,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            cfg=cfg_scale,\n",
        "            sampler_name=sampler_name,\n",
        "            scheduler=scheduler,\n",
        "            positive=positive_out,\n",
        "            negative=negative_out,\n",
        "            latent_image=latent\n",
        "        )[0]\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        try:\n",
        "            print(\"Decoding latents...\")\n",
        "            decoded = vae_decode.decode(vae, sampled)[0]\n",
        "\n",
        "            del vae\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            output_path = \"\"\n",
        "            import datetime\n",
        "            base_name = \"ComfyUI\"\n",
        "            if not overwrite:\n",
        "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                base_name += f\"_{timestamp}\"\n",
        "            if frames == 1:\n",
        "                print(\"Single frame detected - saving as PNG image...\")\n",
        "                output_path = save_as_image(decoded[0], \"ComfyUI\")\n",
        "                # print(f\"Image saved as PNG: {output_path}\")\n",
        "\n",
        "                display(IPImage(filename=output_path))\n",
        "            else:\n",
        "                if output_format.lower() == \"webm\":\n",
        "                    print(\"Saving as WEBM...\")\n",
        "                    output_path = save_as_webm(\n",
        "                        decoded,\n",
        "                        base_name,\n",
        "                        fps=fps,\n",
        "                        codec=\"vp9\",\n",
        "                        quality=10\n",
        "                    )\n",
        "                elif output_format.lower() == \"mp4\":\n",
        "                    print(\"Saving as MP4...\")\n",
        "                    output_path = save_as_mp4(decoded, base_name, fps)\n",
        "\n",
        "                    # output_path = save_as_mp4(decoded, \"ComfyUI\", fps)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported output format: {output_format}\")\n",
        "\n",
        "                # print(f\"Video saved as {output_format.upper()}: {output_path}\")\n",
        "\n",
        "                display_video(output_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during decoding/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "def display_video(video_path):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    video_data = open(video_path,'rb').read()\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    if video_path.lower().endswith('.mp4'):\n",
        "        mime_type = \"video/mp4\"\n",
        "    elif video_path.lower().endswith('.webm'):\n",
        "        mime_type = \"video/webm\"\n",
        "    elif video_path.lower().endswith('.webp'):\n",
        "        mime_type = \"image/webp\"\n",
        "    else:\n",
        "        mime_type = \"video/mp4\"  # default\n",
        "\n",
        "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=512 controls autoplay loop>\n",
        "        <source src=\"{data_url}\" type=\"{mime_type}\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Video\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Video Settings\n",
        "positive_prompt = \"The man is standing still and looking directly at the camera with natural facial expressions and minimal head movement. Subtle breathing motion and blinking. Realistic lighting. Clean background hallway. Eye contact maintained.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"low quality, jpeg artifacts, deformed face, disfigured, mutated hands, broken limbs, distorted proportions, unrealistic eyes, extra fingers, extra limbs, blurry, grainy, noisy, unnatural motion, jerky movement, cartoon, anime, glitch, out of focus, duplicated features, poor anatomy, melted face, doll-like skin, uncanny valley, lip desync, bad teeth, wrong expression, creepy smile, low resolution\" # @param {\"type\":\"string\"}\n",
        "width = 512 # @param {\"type\":\"number\"}\n",
        "height = 512 # @param {\"type\":\"number\"}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 20 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 3 # @param {\"type\":\"number\", \"min\":1, \"max\":20}\n",
        "sampler_name = \"uni_pc\" # @param [\"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "frames = 128 # @param {\"type\":\"integer\", \"min\":1, \"max\":120}\n",
        "fps = 16 # @param {\"type\":\"integer\", \"min\":1, \"max\":60}\n",
        "output_format = \"mp4\" # @param [\"mp4\", \"webm\"]\n",
        "overwrite_previous_video = False # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "# @markdown ### Model Configuration\n",
        "# use_sage_attention = False # @param {type:\"boolean\"}\n",
        "use_sage_attention = False\n",
        "use_flow_shift = True # @param {type:\"boolean\"}\n",
        "flow_shift = 5 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":100.0,\"step\":0.01}\n",
        "# @markdown ---\n",
        "# @markdown ### LoRA Configuration\n",
        "use_lora = True # @param {type:\"boolean\"}\n",
        "LoRA_Strength = 1.0 # @param {\"type\":\"slider\",\"min\":-100,\"max\":100,\"step\":0.01}\n",
        "# @markdown ---\n",
        "# @markdown ### Teacache Settings\n",
        "rel_l1_thresh = 0.3 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":10,\"step\":0.001}\n",
        "start_percent = 0.2 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":1.0,\"step\":0.01}\n",
        "end_percent = 1.0 # @param {\"type\":\"slider\",\"min\":0.0,\"max\":1.0,\"step\":0.01}\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# with torch.inference_mode():\n",
        "generate_video(\n",
        "    image_path=None,\n",
        "    LoRA_Strength=LoRA_Strength,\n",
        "    rel_l1_thresh=rel_l1_thresh,\n",
        "    start_percent=start_percent,\n",
        "    end_percent = end_percent,\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    frames=frames,\n",
        "    fps=fps,\n",
        "    output_format=output_format,\n",
        "    overwrite=overwrite_previous_video,\n",
        "    use_lora = use_lora,\n",
        "    use_sage_attention = use_sage_attention,\n",
        "    enable_flow_shift = use_flow_shift,\n",
        "    shift = flow_shift\n",
        ")\n",
        "clear_memory()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fcsJjujta1K9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}